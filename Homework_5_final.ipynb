{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Visit the Wikipedia hyperlinks graph!\n",
    "\n",
    "## Claudio Battiloro, Daniele Sanna , Carlo Orsellini\n",
    "\n",
    "All the useful functions that we need are in the following .py module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw5_lib as h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some others libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we perform an analysis of the Wikipedia Hyperlink graph. In particular, given extra information about the categories to which an article belongs to, we are curious to rank the articles according to some criteria.\n",
    "\n",
    "For this purpose we use the Wikipedia graph released by the SNAP group.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\"><img src =\"https://www.artribune.com/wp-content/uploads/2016/10/Wikipedia.jpg\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [RQ1] Graph Topology\n",
    "\n",
    "In this section we build the graph $G = (V,E) $ where $V$ is the set of articles and $E$ the hyperlinks among them, and provide its basic information.\n",
    "We implemented a class $Graph_gen$  to achieve the request which contains all the useful infos.\n",
    "Let's just instantiate an object by passing to the constructor the path of the -txt file and explore its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = h.Graph_gen(r\"C:\\Users\\claba\\Desktop\\Python Lavori Congiunti AMDS FDS\\AMDS Works\\Homework 5\\wiki-topcats-reduced.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is it directed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.is_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're dealing with a directed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many nodes has it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many edges has it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is its average degree?\n",
    "\n",
    "The average degree is defined as:\n",
    "$$ \\delta = \\frac{2|E|}{|V|} $$\n",
    "\n",
    "where $|E|$ is the number of edges and $|V|$ is the numebr of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.471"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(graph.avg_degree,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very sparse graph. There are few links w.r.t. the number of nodes. We can check it by computing the graph density that is defined as the number of edges over the maximum possible number of edges:\n",
    "\n",
    "$$ \\rho = \\frac{2|E|}{|V|\\cdot|V-1|} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5e-05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(graph.density,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Block Ranking\n",
    " \n",
    "  ![alt text](http://blogg.loppi.se/babymyran/files/2016/07/Lego.png)\n",
    "     \n",
    " \n",
    "\n",
    " \n",
    "Given a category $C_0 = \\{article_1,\\,article_2,\\,\\dots \\}$ as input we want to rank all of the nodes in V according to the following criteria:\n",
    "\n",
    "$block_{RANKING} =\\begin{bmatrix} C_0 \\\\ C_1 \\\\ \\dots \\\\ C_c\\\\ \\end{bmatrix}$\n",
    "\n",
    "Each category  $C_i$ corresponds  to a list of nodes.\n",
    "\n",
    "The first category of the rank, $C_0$, always corresponds to the input category. The order of the remaining categories is given by:\n",
    "\n",
    "$$distance(C_0, C_i) = median(ShortestPath(C_0, C_i))$$\n",
    "\n",
    "The lower is the distance from $C_0$ the higher is the $C_i$ position in the rank. $ShortestPath(C_0, C_i)$ is the set of all the possible shortest paths between the nodes of $C_0$ and $C_i$. Moreover, the length of a path is given by the sum of the weights of the edges it is composed by that, in this case, we consider unitary.\n",
    "\n",
    "This measure can create some problems if applied on very sparse graphs as the our becouse it doesn't take in account the very big number of ***not-paths***  that are present. In fact, the most of the nodes are not linked to each others.\n",
    "\n",
    "To fix this, we decide to add to the formula a term that is proportional to the number of ***not-paths***  in order to improve the ranking of categories that are more linked and less distant from the input category. The high number of missing paths suggested us to use a logarithmic term:\n",
    "\n",
    "$$ distance(C_0, C_i) = median(ShortestPath(C_0, C_i))\\cdot log_{10}(10 + n_{inf}) $$\n",
    "\n",
    "where $n_{inf}$ is the number of missing links.\n",
    "\n",
    "To double check the procedure and work with optimized tools, we decide to use also *networkx* package to create and manipulate the graph.\n",
    "\n",
    "Let's create the net by first reading the DF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>401135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1069112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>12162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>167659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Destination\n",
       "0      52       401135\n",
       "1      52      1069112\n",
       "2      52      1163551\n",
       "3      62        12162\n",
       "4      62       167659"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv(r'C:\\Users\\claba\\Desktop\\Python Lavori Congiunti AMDS FDS\\AMDS Works\\Homework 5\\wiki-topcats-reduced.txt',sep='\\t',header=None, engine = \"python\")\n",
    "data.columns=['Source','Destination']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use *networkx* and check its properties :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 461193\\nNumber of edges: 2645247\\nAverage in degree:   5.7357\\nAverage out degree:   5.7357'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G=nx.from_pandas_edgelist(data,'Destination','Source',create_using=nx.DiGraph()).to_directed()\n",
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've to clean up the given categories by cutting the ones that have less than 3500 nodes and filtering all the nodes that are not in the current graph. In order to do this, we implemented a function that takes a nx graph and the path of the cat file and returns a dictionary indexed by cathegory with all the valid nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = h.cat_clean(r\"C:\\Users\\claba\\Desktop\\Python Lavori Congiunti AMDS FDS\\AMDS Works\\Homework 5\\wiki-topcats-categories.txt\",G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many categories survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And their dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English_footballers</th>\n",
       "      <td>7538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Football_League_players</th>\n",
       "      <td>7814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Association_football_forwards</th>\n",
       "      <td>5097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Association_football_goalkeepers</th>\n",
       "      <td>3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Association_football_midfielders</th>\n",
       "      <td>5827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Association_football_defenders</th>\n",
       "      <td>4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Living_people</th>\n",
       "      <td>348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_birth_unknown</th>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harvard_University_alumni</th>\n",
       "      <td>5549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major_League_Baseball_pitchers</th>\n",
       "      <td>5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Members_of_the_United_Kingdom_Parliament_for_English_constituencies</th>\n",
       "      <td>6491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indian_films</th>\n",
       "      <td>5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_death_missing</th>\n",
       "      <td>4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_cricketers</th>\n",
       "      <td>3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_birth_missing_(living_people)</th>\n",
       "      <td>28498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rivers_of_Romania</th>\n",
       "      <td>7729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Main_Belt_asteroids</th>\n",
       "      <td>11660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asteroids_named_for_people</th>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English-language_albums</th>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English_television_actors</th>\n",
       "      <td>3362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British_films</th>\n",
       "      <td>4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English-language_films</th>\n",
       "      <td>22463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American_films</th>\n",
       "      <td>15159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fellows_of_the_Royal_Society</th>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People_from_New_York_City</th>\n",
       "      <td>4614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American_Jews</th>\n",
       "      <td>3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American_television_actors</th>\n",
       "      <td>11531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American_film_actors</th>\n",
       "      <td>13865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debut_albums</th>\n",
       "      <td>7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black-and-white_films</th>\n",
       "      <td>10759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_birth_missing</th>\n",
       "      <td>4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Place_of_birth_missing_(living_people)</th>\n",
       "      <td>5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article_Feedback_Pilot</th>\n",
       "      <td>3485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American_military_personnel_of_World_War_II</th>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Windows_games</th>\n",
       "      <td>4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Articles\n",
       "English_footballers                                     7538\n",
       "The_Football_League_players                             7814\n",
       "Association_football_forwards                           5097\n",
       "Association_football_goalkeepers                        3737\n",
       "Association_football_midfielders                        5827\n",
       "Association_football_defenders                          4588\n",
       "Living_people                                         348300\n",
       "Year_of_birth_unknown                                   2536\n",
       "Harvard_University_alumni                               5549\n",
       "Major_League_Baseball_pitchers                          5192\n",
       "Members_of_the_United_Kingdom_Parliament_for_En...      6491\n",
       "Indian_films                                            5568\n",
       "Year_of_death_missing                                   4122\n",
       "English_cricketers                                      3275\n",
       "Year_of_birth_missing_(living_people)                  28498\n",
       "Rivers_of_Romania                                       7729\n",
       "Main_Belt_asteroids                                    11660\n",
       "Asteroids_named_for_people                              4895\n",
       "English-language_albums                                 4760\n",
       "English_television_actors                               3362\n",
       "British_films                                           4422\n",
       "English-language_films                                 22463\n",
       "American_films                                         15159\n",
       "Fellows_of_the_Royal_Society                            3446\n",
       "People_from_New_York_City                               4614\n",
       "American_Jews                                           3411\n",
       "American_television_actors                             11531\n",
       "American_film_actors                                   13865\n",
       "Debut_albums                                            7561\n",
       "Black-and-white_films                                  10759\n",
       "Year_of_birth_missing                                   4346\n",
       "Place_of_birth_missing_(living_people)                  5532\n",
       "Article_Feedback_Pilot                                  3485\n",
       "American_military_personnel_of_World_War_II             3720\n",
       "Windows_games                                           4025"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df = pd.Series({key: len(value) for key, value in cat.items()}).to_frame()\n",
    "cat_df.columns = [\"Articles\"]\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to implement the ranking and we decided to design a ***BFS*** that returns, for each root node, all the reachable nodes with their distance (shortest path) from the root as a  dictionary of the form:\n",
    "\n",
    "$$\\{root : 0,  \\{ reachable-node : shortest-path\\}\\}$$\n",
    "\n",
    "To do this we implemented a function that takes a graph and a root and returns the aforementioned dict. To speed up the process, for this request, it's better working with our \"handmade\" graph that is in the form, for each node:\n",
    "$$\\{node : \\text{list of destination nodes}: [node_i,... ] \\}$$\n",
    "\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12162, 167659, 279122, 1089199, 1354553, 1400636, 1403619, 1537692, 1544420]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the BFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301542"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The node 52 has the following number of reachable nodes:\n",
    "len(h.bfs(graph.graph, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking process can be huge, so we decided to implement an inverted index that is indexed by node and contains their categories. This drastically speeds up the process. \n",
    "\n",
    "$$ \\{ \\text{node-number : node-category} \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_index = h.cat_inverted_index(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the ranking by using a function that takes the categories dic, the input category name, the inverted index and the graph and returns a dictionary containing tha ranking that we can present in a nicer way using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_cricketers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English_television_actors</td>\n",
       "      <td>15.884298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Members_of_the_United_Kingdom_Parliament_for_E...</td>\n",
       "      <td>17.194176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Article_Feedback_Pilot</td>\n",
       "      <td>17.591797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fellows_of_the_Royal_Society</td>\n",
       "      <td>18.483759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>American_Jews</td>\n",
       "      <td>18.785860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>18.886058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>18.893466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian_films</td>\n",
       "      <td>18.952991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>American_military_personnel_of_World_War_II</td>\n",
       "      <td>18.995026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>20.141888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>British_films</td>\n",
       "      <td>21.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Windows_games</td>\n",
       "      <td>21.898795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Year_of_birth_unknown</td>\n",
       "      <td>22.754647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>English-language_albums</td>\n",
       "      <td>22.828840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>American_films</td>\n",
       "      <td>22.853315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>23.025562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>23.050442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Major_League_Baseball_pitchers</td>\n",
       "      <td>23.395577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rivers_of_Romania</td>\n",
       "      <td>23.547956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Harvard_University_alumni</td>\n",
       "      <td>24.142026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>24.311342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>24.585626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Year_of_death_missing</td>\n",
       "      <td>24.837866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Association_football_goalkeepers</td>\n",
       "      <td>24.883120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>25.547388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>25.789518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>26.306021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>26.993294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>27.082978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>27.902070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Year_of_birth_missing_(living_people)</td>\n",
       "      <td>28.980035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>31.905536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Main_Belt_asteroids</td>\n",
       "      <td>36.061274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Living_people</td>\n",
       "      <td>36.542935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Category     Scores\n",
       "0                                  English_cricketers   0.000000\n",
       "1                           English_television_actors  15.884298\n",
       "2   Members_of_the_United_Kingdom_Parliament_for_E...  17.194176\n",
       "3                              Article_Feedback_Pilot  17.591797\n",
       "4                        Fellows_of_the_Royal_Society  18.483759\n",
       "5                                       American_Jews  18.785860\n",
       "6                               Black-and-white_films  18.886058\n",
       "7                                American_film_actors  18.893466\n",
       "8                                        Indian_films  18.952991\n",
       "9         American_military_personnel_of_World_War_II  18.995026\n",
       "10                          People_from_New_York_City  20.141888\n",
       "11                                      British_films  21.508700\n",
       "12                                      Windows_games  21.898795\n",
       "13                              Year_of_birth_unknown  22.754647\n",
       "14                            English-language_albums  22.828840\n",
       "15                                     American_films  22.853315\n",
       "16                                       Debut_albums  23.025562\n",
       "17             Place_of_birth_missing_(living_people)  23.050442\n",
       "18                     Major_League_Baseball_pitchers  23.395577\n",
       "19                                  Rivers_of_Romania  23.547956\n",
       "20                          Harvard_University_alumni  24.142026\n",
       "21                              Year_of_birth_missing  24.311342\n",
       "22                             English-language_films  24.585626\n",
       "23                              Year_of_death_missing  24.837866\n",
       "24                   Association_football_goalkeepers  24.883120\n",
       "25                     Association_football_defenders  25.547388\n",
       "26                      Association_football_forwards  25.789518\n",
       "27                   Association_football_midfielders  26.306021\n",
       "28                                English_footballers  26.993294\n",
       "29                        The_Football_League_players  27.082978\n",
       "30                         American_television_actors  27.902070\n",
       "31              Year_of_birth_missing_(living_people)  28.980035\n",
       "32                         Asteroids_named_for_people  31.905536\n",
       "33                                Main_Belt_asteroids  36.061274\n",
       "34                                      Living_people  36.542935"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = h.block_ranking(cat,'English_cricketers',rev_index,graph.graph)\n",
    "rank_ = pd.DataFrame(rank, columns=['Category','Scores'])\n",
    "rank_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Ranking\n",
    "\n",
    "\n",
    "![image](https://i.pinimg.com/originals/2e/79/d3/2e79d322842b063b0d620b5de334ab1a.gif)\n",
    "\n",
    "\n",
    "Once we obtain the $block_{RANKING}$ vector, we want to sort the nodes in each category. To do this, we follow the steps indicated:\n",
    "\n",
    "[**STEP 1**] : Compute subgraph induced by $C_0$. For each node compute the sum of the weigths of the in-edges.\n",
    "\n",
    "$$score_{article_j} = \\sum_{j \\in in-edges(article_i)} w_j$$\n",
    "\n",
    "[**STEP2**] Extend the graph to the nodes that belong to $C_1$. Thus, for each article in $C_1$ compute the score as before. Note that the in-edges coming from the previous category, $C_0$, have as weights the score of the node that sends the edge.\n",
    "\n",
    "[**STEP3**] Repeat Step2 up to the last category of the ranking.\n",
    "\n",
    "This 3 steps are implemented in a function that takes the categories dic, the graph and the categories names ordere by block ranking and returns the node ranking as a dictionary of the form:\n",
    "\n",
    "$$ \\{ category : \\{ node : weights-sum \\} \\} $$\n",
    "\n",
    "Where the categories are in the order of the block ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(h)\n",
    "node_rank = h.node_ranking(cat,G, rank_.Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be interesting to see which are the articles that obtained the highest overall scores.\n",
    "To this we implemented a function that takes the *node_rank* dic and the path of the article names file and return a dataframe containing the overall ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johnny Weir</td>\n",
       "      <td>10632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jean-Claude Merlin</td>\n",
       "      <td>10578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frank Shu</td>\n",
       "      <td>10576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ora Lassila</td>\n",
       "      <td>10572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oliver Morton (science writer)</td>\n",
       "      <td>10572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Article  Scores\n",
       "0                     Johnny Weir   10632\n",
       "1              Jean-Claude Merlin   10578\n",
       "2                       Frank Shu   10576\n",
       "3                     Ora Lassila   10572\n",
       "4  Oliver Morton (science writer)   10572"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ = h.name_matching(node_rank, r\"C:\\Users\\claba\\Desktop\\Python Lavori Congiunti AMDS FDS\\AMDS Works\\Homework 5\\wiki-topcats-page-names.txt\" )\n",
    "name_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Signal Processing on Graph\n",
    "\n",
    "In this small Appendix we wanna suggest some tools that can be very useful to go deeper in this kind of analysis and that come from other disciplinar sectors, like signal processing. \n",
    "\n",
    "Nowadays, applications such as social, energy, transportation, sensor,and neuronal networks, high-dimensional data and ,of course, financial data naturally reside on the vertices of weighted graphs. The emerging field of [signal processing on graphs](https://arxiv.org/abs/1211.0053) merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs.\n",
    "\n",
    "We don't want to introduce the math behind this interesting theory but, just for completeness in the definition, a signal on a graph is defined as a *map* from the set $V$ of nodes into the set of complex numbers $\\mathbb{C}$:\n",
    "$$\\mathbb{s}: V \\rightarrow \\mathbb{C}$$\n",
    "$$\\mathbf{s} = [s_1,...,s_{|V|}]^T$$\n",
    "\n",
    "each element $s_n$ being indexed by node $n$.\n",
    "\n",
    "It's possible to define signals also on the edges (or on nodes tripletes) and they can be very useful to describe epidemology and (discrete) diffusion in huge networks.\n",
    "\n",
    "Otherwise, using the [sampling theory for signals on graph](https://arxiv.org/abs/1503.05432) we can try to reconstruct (or predict) missing data by knowing the graph and the values of a finite number of other components ( we can reconstruct a full signal by an its subsampled version) and this can be done by using only the current day data or an entire time series . This procedure are guaranteed and can be extended to more sophisticated application (more on, just to mention one active researcher, [Gonzalo Mateos](https://www.researchgate.net/scientific-contributions/2049675778_Gonzalo_Mateos) page).\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
